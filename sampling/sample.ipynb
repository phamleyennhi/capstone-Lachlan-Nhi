{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "286de4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c105f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_word = ['one','two','three','four','five','six','seven','eight','nine','ten','eleven','twelve','thirteen']\n",
    "def sample_from_file(annotator_name, sample_from, num_samples, sample_size = 100):\n",
    "    with open('file_mapping.pkl', 'rb') as f:\n",
    "        file_mappings = pickle.load(f)\n",
    "    if annotator_name not in file_mappings:\n",
    "        file_mappings[annotator_name] = {}\n",
    "    if sample_from not in file_mappings[annotator_name]:\n",
    "        file_mappings[annotator_name][sample_from] = []\n",
    "    \n",
    "    cnt = len(glob.glob(f\"{annotator_name}/*\"))\n",
    "    df = pd.read_csv(sample_from, index_col = 'Unnamed: 0').sample(num_samples * sample_size, random_state = 1)\n",
    "    df = df[df['cleaned_content'].str.count(' ').gt(4)]\n",
    "    dfs = np.array_split(df, num_samples)\n",
    "    for sample in dfs:\n",
    "        filename = f\"{annotator_name}_{num_to_word[cnt]}.csv\"\n",
    "        sample.to_csv(f\"{annotator_name}/{filename}\")\n",
    "        cnt += 1\n",
    "        file_mappings[annotator_name][sample_from].append(filename)\n",
    "        \n",
    "    with open('file_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(file_mappings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3ecb83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>english_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-01-01 23:58:44+00:00</td>\n",
       "      <td>@griff__00 Bro! We be too relaxed for this sid...</td>\n",
       "      <td>bro we be too relaxed for this side we make am...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2022-01-01 23:57:40+00:00</td>\n",
       "      <td>Okay so make king promise start dey use Egusi ...</td>\n",
       "      <td>okay so make king promise start dey use egusi ...</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-01-01 23:56:32+00:00</td>\n",
       "      <td>I’ll post a lot this year. \\niMean pictures of...</td>\n",
       "      <td>ill post a lot this year imean pictures of myself</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>2022-01-01 23:53:36+00:00</td>\n",
       "      <td>Exactly!! Shatta made him in his image and lik...</td>\n",
       "      <td>exactly shatta made him in his image and liken...</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>2022-01-01 23:51:26+00:00</td>\n",
       "      <td>We chop the Xmas and new yr finish biaa .\\nNow...</td>\n",
       "      <td>we chop the xmas and new yr finish biaa now le...</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24235</td>\n",
       "      <td>2022-08-31 23:40:50+00:00</td>\n",
       "      <td>As ah plan sey I won take u out nor duh b all ...</td>\n",
       "      <td>as ah plan sey i won take u out nor duh b all ...</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>24249</td>\n",
       "      <td>2022-08-31 23:32:08+00:00</td>\n",
       "      <td>Even well-designed initiatives can fall apart ...</td>\n",
       "      <td>even well designed initiatives can fall apart ...</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>24251</td>\n",
       "      <td>2022-08-31 23:31:08+00:00</td>\n",
       "      <td>Educational technology initiatives also bring ...</td>\n",
       "      <td>educational technology initiatives also bring ...</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>24256</td>\n",
       "      <td>2022-08-31 23:29:29+00:00</td>\n",
       "      <td>This is when some party men left us to our fai...</td>\n",
       "      <td>this is when some party men left us to our fai...</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>24300</td>\n",
       "      <td>2022-08-31 23:12:30+00:00</td>\n",
       "      <td>One of the worst betrayals is Ginger posing as...</td>\n",
       "      <td>one of the worst betrayals is ginger posing as...</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       date  \\\n",
       "5       6  2022-01-01 23:58:44+00:00   \n",
       "11     12  2022-01-01 23:57:40+00:00   \n",
       "12     13  2022-01-01 23:56:32+00:00   \n",
       "30     31  2022-01-01 23:53:36+00:00   \n",
       "38     39  2022-01-01 23:51:26+00:00   \n",
       "..    ...                        ...   \n",
       "34  24235  2022-08-31 23:40:50+00:00   \n",
       "48  24249  2022-08-31 23:32:08+00:00   \n",
       "50  24251  2022-08-31 23:31:08+00:00   \n",
       "55  24256  2022-08-31 23:29:29+00:00   \n",
       "99  24300  2022-08-31 23:12:30+00:00   \n",
       "\n",
       "                                           rawContent  \\\n",
       "5   @griff__00 Bro! We be too relaxed for this sid...   \n",
       "11  Okay so make king promise start dey use Egusi ...   \n",
       "12  I’ll post a lot this year. \\niMean pictures of...   \n",
       "30  Exactly!! Shatta made him in his image and lik...   \n",
       "38  We chop the Xmas and new yr finish biaa .\\nNow...   \n",
       "..                                                ...   \n",
       "34  As ah plan sey I won take u out nor duh b all ...   \n",
       "48  Even well-designed initiatives can fall apart ...   \n",
       "50  Educational technology initiatives also bring ...   \n",
       "55  This is when some party men left us to our fai...   \n",
       "99  One of the worst betrayals is Ginger posing as...   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "5   bro we be too relaxed for this side we make am...   \n",
       "11  okay so make king promise start dey use egusi ...   \n",
       "12  ill post a lot this year imean pictures of myself   \n",
       "30  exactly shatta made him in his image and liken...   \n",
       "38  we chop the xmas and new yr finish biaa now le...   \n",
       "..                                                ...   \n",
       "34  as ah plan sey i won take u out nor duh b all ...   \n",
       "48  even well designed initiatives can fall apart ...   \n",
       "50  educational technology initiatives also bring ...   \n",
       "55  this is when some party men left us to our fai...   \n",
       "99  one of the worst betrayals is ginger posing as...   \n",
       "\n",
       "    english_relative_frequency  \n",
       "5                     0.933333  \n",
       "11                    0.928571  \n",
       "12                    0.900000  \n",
       "30                    0.937500  \n",
       "38                    0.937500  \n",
       "..                         ...  \n",
       "34                    0.956522  \n",
       "48                    0.954545  \n",
       "50                    0.944444  \n",
       "55                    0.978723  \n",
       "99                    0.916667  \n",
       "\n",
       "[2132 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_from = \"/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Accra/24400_tweets_over_period/0.9_to_1.0_english_words.csv\"\n",
    "df1 = pd.read_csv(sample_from, index_col = 'Unnamed: 0')\n",
    "df1\n",
    "# df1[df1['cleaned_content'].str.count(' ').gt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "321b876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_file(\"abbas\", sample_from, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4bc4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abbas': {'/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Accra/24400_tweets_over_period/0.7_to_0.8_english_words.csv': ['abbas_one.csv',\n",
       "   'abbas_two.csv',\n",
       "   'abbas_three.csv',\n",
       "   'abbas_four.csv',\n",
       "   'abbas_five.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Accra/24400_tweets_over_period/0.8_to_0.9_english_words.csv': ['abbas_six.csv',\n",
       "   'abbas_seven.csv',\n",
       "   'abbas_eight.csv',\n",
       "   'abbas_nine.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Accra/24400_tweets_over_period/0.9_to_1.0_english_words.csv': ['abbas_ten.csv',\n",
       "   'abbas_eleven.csv',\n",
       "   'abbas_twelve.csv',\n",
       "   'abbas_thirteen.csv']},\n",
       " 'manahil': {'/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Islamabad/24400_tweets_over_period/0.6_to_0.7_english_words.csv': ['manahil_one.csv',\n",
       "   'manahil_two.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Islamabad/24400_tweets_over_period/0.9_to_1.0_english_words.csv': ['manahil_three.csv',\n",
       "   'manahil_four.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Islamabad/24400_tweets_over_period/0.8_to_0.9_english_words.csv': ['manahil_five.csv',\n",
       "   'manahil_six.csv',\n",
       "   'manahil_seven.csv',\n",
       "   'manahil_eight.csv']},\n",
       " 'zain': {'/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Islamabad/24400_tweets_over_period/0.7_to_0.8_english_words.csv': ['zain_one.csv',\n",
       "   'zain_two.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/New Delhi/24400_tweets_over_period/0.7_to_0.8_english_words.csv': ['zain_three.csv',\n",
       "   'zain_four.csv',\n",
       "   'zain_five.csv',\n",
       "   'zain_six.csv',\n",
       "   'zain_seven.csv',\n",
       "   'zain_eight.csv']},\n",
       " 'quim': {'/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Manila/24400_tweets_over_period/0.7_to_0.8_english_words.csv': ['quim_one.csv',\n",
       "   'quim_two.csv',\n",
       "   'quim_three.csv',\n",
       "   'quim_four.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Manila/24400_tweets_over_period/0.8_to_0.9_english_words.csv': ['quim_five.csv',\n",
       "   'quim_six.csv',\n",
       "   'quim_seven.csv'],\n",
       "  '/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/Manila/24400_tweets_over_period/0.9_to_1.0_english_words.csv': ['quim_eight.csv',\n",
       "   'quim_nine.csv',\n",
       "   'quim_ten.csv']},\n",
       " 'maimuna': {'/Users/lachlanpham/Documents/App Folders/GitHub/capstone-Lachlan-Nhi/data/New Delhi/24400_tweets_over_period/0.8_to_0.9_english_words.csv': ['maimuna_one.csv',\n",
       "   'maimuna_two.csv',\n",
       "   'maimuna_three.csv',\n",
       "   'maimuna_four.csv',\n",
       "   'maimuna_five.csv']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('file_mapping.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d04ec026",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../first_annotation/Annotators/abbas_two.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-74eeac8f9572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlist_of_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcsv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_csv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../first_annotation/Annotators/{csv}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../first_annotation/Annotators/abbas_two.csv'"
     ]
    }
   ],
   "source": [
    "for mapping in mappings:\n",
    "    item = mappings[mapping]\n",
    "    for path in item:\n",
    "        temp = fname.split('/')\n",
    "        country = temp[-3]\n",
    "        interval = temp[-1]\n",
    "        temp_path_list = os.path.dirname(path).split('/')\n",
    "        temp_path_list[7] = 'first_annotation'\n",
    "        outdirs = '/'.join(temp_path_list[7:])\n",
    "        basename = os.path.basename(path)\n",
    "        os.makedirs(outdirs, exist_ok = True)\n",
    "        output_path = os.path.join(outdirs, basename)\n",
    "        \n",
    "        list_of_csv = item[path]\n",
    "        for csv in list_of_csv:\n",
    "            df = pd.read_csv(f\"../first_annotation/Annotators/{csv}\")\n",
    "            df.head(10)\n",
    "                \n",
    "#         with open(output_path, 'a') as f_object:\n",
    "#             for csv in list_of_csv:\n",
    "#                 df = pd.read_csv(f\"first_annotation/Annotators/{csv}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb16e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea083a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
