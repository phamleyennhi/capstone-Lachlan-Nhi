{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64bfc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_words_list = []\n",
    "\n",
    "with open('english_words_corpora/english_corpus.csv', 'r') as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    list_of_csv = list(csv_reader)\n",
    "    english_words_list = list_of_csv[0]      \n",
    "english_words_set = set(english_words_list)\n",
    "\n",
    "\n",
    "def create_relative_english_frequency_col(df):\n",
    "    def calculate_relative_frequency(content):\n",
    "        english_word_bools = [lemmatizer.lemmatize(word) in english_words_set for word in str(content).split() if word.isalpha()]\n",
    "        if not english_word_bools:\n",
    "            return 0\n",
    "        return english_word_bools.count(True)/len(english_word_bools) \n",
    "    df[\"english_relative_frequency\"] = df.cleaned_content.apply(calculate_relative_frequency)\n",
    "    return df\n",
    "\n",
    "def filter_by_english_thresholds(min_thresh, max_thresh, original_dataset, create_file = False):\n",
    "    output_dir = os.path.splitext(original_dataset)[0]\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    with open(original_dataset, \"r\") as infile:\n",
    "        source_df = pd.read_csv(infile, index_col=[0])\n",
    "        out_df = create_relative_english_frequency_col(source_df)\n",
    "        out_df = out_df[(min_thresh <= out_df[\"english_relative_frequency\"]) & (out_df[\"english_relative_frequency\"] < max_thresh)]\n",
    "    \n",
    "    if create_file: \n",
    "        with open(output_dir + f\"/{min_thresh}_to_{max_thresh}_english_words.csv\", \"w\") as outfile:\n",
    "            outfile.write(out_df.to_csv())\n",
    "            \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0a643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>english_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-01 23:57:20+00:00</td>\n",
       "      <td>@Siennafrst I survived another year without tr...</td>\n",
       "      <td>i survived another year without travel in the ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2022-01-01 23:56:08+00:00</td>\n",
       "      <td>#とき宣お正月 #超ときめき宣伝部 \\n??? https://t.co/UZA8k8PSi9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-01-01 23:55:49+00:00</td>\n",
       "      <td>おはようございます😊\\n今日は、これから息子の学校のペンキ塗りと荷物運び❗\\nお正月ってどこ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-01-01 23:52:10+00:00</td>\n",
       "      <td>@afrorakda ありがとうございます🥰\\n普通に遊べて楽しいじゃないか～と自画自賛して...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2022-01-01 23:52:01+00:00</td>\n",
       "      <td>@Khithitofficial လေးစားပါတယ်\\nသန်း‌ေြခာက်ဆယ်သြ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>24193</td>\n",
       "      <td>2022-08-31 22:48:29+00:00</td>\n",
       "      <td>Breakfast (@ Beach Road Kitchen) https://t.co/...</td>\n",
       "      <td>breakfast beach road kitchen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>24194</td>\n",
       "      <td>2022-08-31 22:47:16+00:00</td>\n",
       "      <td>All the replies are complaints (I think 8 is a...</td>\n",
       "      <td>all the replies are complaints i think 8 is a ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24196</td>\n",
       "      <td>2022-08-31 22:44:03+00:00</td>\n",
       "      <td>@Mohamed08334779 Masha allah</td>\n",
       "      <td>masha allah</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>24197</td>\n",
       "      <td>2022-08-31 22:42:29+00:00</td>\n",
       "      <td>NOPE https://t.co/G4YfsotYO0</td>\n",
       "      <td>nope</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24199</td>\n",
       "      <td>2022-08-31 22:40:59+00:00</td>\n",
       "      <td>Hold on tight to the ones you love. Life is fl...</td>\n",
       "      <td>hold on tight to the ones you love life is fle...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12927 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       date  \\\n",
       "7       8  2022-01-01 23:57:20+00:00   \n",
       "8       9  2022-01-01 23:56:08+00:00   \n",
       "9      10  2022-01-01 23:55:49+00:00   \n",
       "12     13  2022-01-01 23:52:10+00:00   \n",
       "13     14  2022-01-01 23:52:01+00:00   \n",
       "..    ...                        ...   \n",
       "92  24193  2022-08-31 22:48:29+00:00   \n",
       "93  24194  2022-08-31 22:47:16+00:00   \n",
       "95  24196  2022-08-31 22:44:03+00:00   \n",
       "96  24197  2022-08-31 22:42:29+00:00   \n",
       "98  24199  2022-08-31 22:40:59+00:00   \n",
       "\n",
       "                                           rawContent  \\\n",
       "7   @Siennafrst I survived another year without tr...   \n",
       "8     #とき宣お正月 #超ときめき宣伝部 \\n??? https://t.co/UZA8k8PSi9   \n",
       "9   おはようございます😊\\n今日は、これから息子の学校のペンキ塗りと荷物運び❗\\nお正月ってどこ...   \n",
       "12  @afrorakda ありがとうございます🥰\\n普通に遊べて楽しいじゃないか～と自画自賛して...   \n",
       "13  @Khithitofficial လေးစားပါတယ်\\nသန်း‌ေြခာက်ဆယ်သြ...   \n",
       "..                                                ...   \n",
       "92  Breakfast (@ Beach Road Kitchen) https://t.co/...   \n",
       "93  All the replies are complaints (I think 8 is a...   \n",
       "95                       @Mohamed08334779 Masha allah   \n",
       "96                       NOPE https://t.co/G4YfsotYO0   \n",
       "98  Hold on tight to the ones you love. Life is fl...   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "7   i survived another year without travel in the ...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "..                                                ...   \n",
       "92                       breakfast beach road kitchen   \n",
       "93  all the replies are complaints i think 8 is a ...   \n",
       "95                                        masha allah   \n",
       "96                                               nope   \n",
       "98  hold on tight to the ones you love life is fle...   \n",
       "\n",
       "    english_relative_frequency  \n",
       "7                          1.0  \n",
       "8                          1.0  \n",
       "9                          1.0  \n",
       "12                         1.0  \n",
       "13                         1.0  \n",
       "..                         ...  \n",
       "92                         1.0  \n",
       "93                         1.0  \n",
       "95                         1.0  \n",
       "96                         1.0  \n",
       "98                         1.0  \n",
       "\n",
       "[12927 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    filter_by_english_thresholds(i/10, (i+1)/10, \"data/Singapore/tweets_over_period/24400_tweets_over_period.csv\", create_file = True)\n",
    "filter_by_english_thresholds(1, 1.01, \"data/Singapore/tweets_over_period/24400_tweets_over_period.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
