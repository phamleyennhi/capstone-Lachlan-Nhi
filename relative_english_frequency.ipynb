{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bfc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_words_list = []\n",
    "\n",
    "with open('english_words_corpora/english_corpus.csv', 'r') as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    list_of_csv = list(csv_reader)\n",
    "    english_words_list = list_of_csv[0]      \n",
    "english_words_set = set(english_words_list)\n",
    "\n",
    "\n",
    "def create_relative_english_frequency_col(df):\n",
    "    def calculate_relative_frequency(content):\n",
    "        english_word_bools = [lemmatizer.lemmatize(word) in english_words_set for word in str(content).split() if word.isalpha()]\n",
    "        if not english_word_bools:\n",
    "            return 0\n",
    "        return english_word_bools.count(True)/len(english_word_bools) \n",
    "    df[\"english_relative_frequency\"] = df.cleaned_content.apply(calculate_relative_frequency)\n",
    "    return df\n",
    "\n",
    "def filter_by_english_thresholds(min_thresh, max_thresh, original_dataset, create_file = False):\n",
    "    output_dir = os.path.splitext(original_dataset)[0]\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    with open(original_dataset, \"r\") as infile:\n",
    "        source_df = pd.read_csv(infile, index_col=[0])\n",
    "        out_df = create_relative_english_frequency_col(source_df)\n",
    "        out_df = out_df[(min_thresh <= out_df[\"english_relative_frequency\"]) & (out_df[\"english_relative_frequency\"] < max_thresh)]\n",
    "    \n",
    "    if create_file: \n",
    "        with open(output_dir + f\"/{min_thresh}_to_{max_thresh}_english_words.csv\", \"w\") as outfile:\n",
    "            outfile.write(out_df.to_csv())\n",
    "            \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0a643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>english_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01 23:59:12+00:00</td>\n",
       "      <td>@kay_bee28 üòÇüòÇ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 23:59:07+00:00</td>\n",
       "      <td>@shattawalegh Sell Out</td>\n",
       "      <td>sell out</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 23:58:29+00:00</td>\n",
       "      <td>Happy new year baby ‚ù§Ô∏èüòç https://t.co/xAG3pa8O86</td>\n",
       "      <td>happy new year baby</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-01 23:58:16+00:00</td>\n",
       "      <td>@Airkuya JonüòÜ</td>\n",
       "      <td>jon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-01-01 23:57:45+00:00</td>\n",
       "      <td>The space way time them go close?</td>\n",
       "      <td>the space way time them go close</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>24295</td>\n",
       "      <td>2022-08-31 23:13:51+00:00</td>\n",
       "      <td>#GodDid https://t.co/x1cFRzDCVa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24296</td>\n",
       "      <td>2022-08-31 23:13:46+00:00</td>\n",
       "      <td>@jordan1zz Okay sure thank you</td>\n",
       "      <td>okay sure thank you</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>24297</td>\n",
       "      <td>2022-08-31 23:13:38+00:00</td>\n",
       "      <td>@cfcjakes @okoyeKennedy4 @Harriso58693132 @Abs...</td>\n",
       "      <td>he signed this season rather</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>24298</td>\n",
       "      <td>2022-08-31 23:13:37+00:00</td>\n",
       "      <td>@1RealJunior_ I am waiting</td>\n",
       "      <td>i am waiting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24299</td>\n",
       "      <td>2022-08-31 23:12:33+00:00</td>\n",
       "      <td>Just posted a photo @ Accra, Ghana https://t.c...</td>\n",
       "      <td>just posted a photo accra ghana</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15905 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       date  \\\n",
       "2       3  2022-01-01 23:59:12+00:00   \n",
       "3       4  2022-01-01 23:59:07+00:00   \n",
       "6       7  2022-01-01 23:58:29+00:00   \n",
       "7       8  2022-01-01 23:58:16+00:00   \n",
       "9      10  2022-01-01 23:57:45+00:00   \n",
       "..    ...                        ...   \n",
       "94  24295  2022-08-31 23:13:51+00:00   \n",
       "95  24296  2022-08-31 23:13:46+00:00   \n",
       "96  24297  2022-08-31 23:13:38+00:00   \n",
       "97  24298  2022-08-31 23:13:37+00:00   \n",
       "98  24299  2022-08-31 23:12:33+00:00   \n",
       "\n",
       "                                           rawContent  \\\n",
       "2                                       @kay_bee28 üòÇüòÇ   \n",
       "3                              @shattawalegh Sell Out   \n",
       "6     Happy new year baby ‚ù§Ô∏èüòç https://t.co/xAG3pa8O86   \n",
       "7                                       @Airkuya JonüòÜ   \n",
       "9                   The space way time them go close?   \n",
       "..                                                ...   \n",
       "94                    #GodDid https://t.co/x1cFRzDCVa   \n",
       "95                     @jordan1zz Okay sure thank you   \n",
       "96  @cfcjakes @okoyeKennedy4 @Harriso58693132 @Abs...   \n",
       "97                         @1RealJunior_ I am waiting   \n",
       "98  Just posted a photo @ Accra, Ghana https://t.c...   \n",
       "\n",
       "                     cleaned_content  english_relative_frequency  \n",
       "2                                NaN                         1.0  \n",
       "3                           sell out                         1.0  \n",
       "6                happy new year baby                         1.0  \n",
       "7                                jon                         1.0  \n",
       "9   the space way time them go close                         1.0  \n",
       "..                               ...                         ...  \n",
       "94                               NaN                         1.0  \n",
       "95               okay sure thank you                         1.0  \n",
       "96      he signed this season rather                         1.0  \n",
       "97                      i am waiting                         1.0  \n",
       "98   just posted a photo accra ghana                         1.0  \n",
       "\n",
       "[15905 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    filter_by_english_thresholds(i/10, (i+1)/10, 'data/Accra/24400_tweets_over_period.csv', create_file = True)\n",
    "filter_by_english_thresholds(1, 1.01, 'data/Accra/24400_tweets_over_period.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
