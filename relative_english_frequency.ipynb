{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bfc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_words_list = []\n",
    "\n",
    "with open('english_words_corpora/english_corpus.csv', 'r') as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    list_of_csv = list(csv_reader)\n",
    "    english_words_list = list_of_csv[0]      \n",
    "english_words_set = set(english_words_list)\n",
    "\n",
    "\n",
    "def create_relative_english_frequency_col(df):\n",
    "    def calculate_relative_frequency(content):\n",
    "        english_word_bools = [lemmatizer.lemmatize(word) in english_words_set for word in str(content).split() if word.isalpha()]\n",
    "        if not english_word_bools:\n",
    "            return 0\n",
    "        return english_word_bools.count(True)/len(english_word_bools) \n",
    "    df[\"english_relative_frequency\"] = df.cleaned_content.apply(calculate_relative_frequency)\n",
    "    return df\n",
    "\n",
    "def filter_by_english_thresholds(min_thresh, max_thresh, original_dataset, create_file = False):\n",
    "    output_dir = os.path.splitext(original_dataset)[0]\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    with open(original_dataset, \"r\") as infile:\n",
    "        source_df = pd.read_csv(infile, index_col=[0])\n",
    "        out_df = create_relative_english_frequency_col(source_df)\n",
    "        out_df = out_df[(min_thresh <= out_df[\"english_relative_frequency\"]) & (out_df[\"english_relative_frequency\"] < max_thresh)]\n",
    "    \n",
    "    if create_file: \n",
    "        with open(output_dir + f\"/{min_thresh}_to_{max_thresh}_english_words.csv\", \"w\") as outfile:\n",
    "            outfile.write(out_df.to_csv())\n",
    "            \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0a643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>english_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01 23:56:48+00:00</td>\n",
       "      <td>@Dark_Emperorr A who fi cook it?</td>\n",
       "      <td>a who fi cook it</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 23:53:04+00:00</td>\n",
       "      <td>Very reassuring and genuine. A rallying cry fo...</td>\n",
       "      <td>very reassuring and genuine a rallying cry for...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-01-01 23:51:04+00:00</td>\n",
       "      <td>Excellent #PNPSTRONG with @MarkJGolding . http...</td>\n",
       "      <td>excellent with</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 23:50:41+00:00</td>\n",
       "      <td>Just remembered today is not Sunday. Was looki...</td>\n",
       "      <td>just remembered today is not sunday was lookin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2022-01-01 23:47:58+00:00</td>\n",
       "      <td>Book now ‚õ±Ô∏èüèùÔ∏è https://t.co/BmNHqd3dPg</td>\n",
       "      <td>book now</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>24294</td>\n",
       "      <td>2022-08-31 22:37:44+00:00</td>\n",
       "      <td>Escape plan https://t.co/gb8AlfMiTC</td>\n",
       "      <td>escape plan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>24295</td>\n",
       "      <td>2022-08-31 22:36:33+00:00</td>\n",
       "      <td>The Grey https://t.co/EsChAtTh3Y</td>\n",
       "      <td>the grey</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24296</td>\n",
       "      <td>2022-08-31 22:34:49+00:00</td>\n",
       "      <td>@MayDenn88559924 @jayjaybrown97 Not really the...</td>\n",
       "      <td>not really the uk 5 note changed to polymer in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>24298</td>\n",
       "      <td>2022-08-31 22:33:17+00:00</td>\n",
       "      <td>@indramistress meeee !!!!</td>\n",
       "      <td>meeee</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24299</td>\n",
       "      <td>2022-08-31 22:30:53+00:00</td>\n",
       "      <td>@possibilityboss @AdvocateAndria @ChampionPrez...</td>\n",
       "      <td>i always wondered about that allowance</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16605 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       date  \\\n",
       "2       3  2022-01-01 23:56:48+00:00   \n",
       "3       4  2022-01-01 23:53:04+00:00   \n",
       "5       6  2022-01-01 23:51:04+00:00   \n",
       "6       7  2022-01-01 23:50:41+00:00   \n",
       "10     11  2022-01-01 23:47:58+00:00   \n",
       "..    ...                        ...   \n",
       "93  24294  2022-08-31 22:37:44+00:00   \n",
       "94  24295  2022-08-31 22:36:33+00:00   \n",
       "95  24296  2022-08-31 22:34:49+00:00   \n",
       "97  24298  2022-08-31 22:33:17+00:00   \n",
       "98  24299  2022-08-31 22:30:53+00:00   \n",
       "\n",
       "                                           rawContent  \\\n",
       "2                    @Dark_Emperorr A who fi cook it?   \n",
       "3   Very reassuring and genuine. A rallying cry fo...   \n",
       "5   Excellent #PNPSTRONG with @MarkJGolding . http...   \n",
       "6   Just remembered today is not Sunday. Was looki...   \n",
       "10              Book now ‚õ±Ô∏èüèùÔ∏è https://t.co/BmNHqd3dPg   \n",
       "..                                                ...   \n",
       "93                Escape plan https://t.co/gb8AlfMiTC   \n",
       "94                   The Grey https://t.co/EsChAtTh3Y   \n",
       "95  @MayDenn88559924 @jayjaybrown97 Not really the...   \n",
       "97                          @indramistress meeee !!!!   \n",
       "98  @possibilityboss @AdvocateAndria @ChampionPrez...   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "2                                    a who fi cook it   \n",
       "3   very reassuring and genuine a rallying cry for...   \n",
       "5                                      excellent with   \n",
       "6   just remembered today is not sunday was lookin...   \n",
       "10                                           book now   \n",
       "..                                                ...   \n",
       "93                                        escape plan   \n",
       "94                                           the grey   \n",
       "95  not really the uk 5 note changed to polymer in...   \n",
       "97                                              meeee   \n",
       "98             i always wondered about that allowance   \n",
       "\n",
       "    english_relative_frequency  \n",
       "2                          1.0  \n",
       "3                          1.0  \n",
       "5                          1.0  \n",
       "6                          1.0  \n",
       "10                         1.0  \n",
       "..                         ...  \n",
       "93                         1.0  \n",
       "94                         1.0  \n",
       "95                         1.0  \n",
       "97                         1.0  \n",
       "98                         1.0  \n",
       "\n",
       "[16605 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    filter_by_english_thresholds(i/10, (i+1)/10, 'data/Kingston/24400_tweets_over_period.csv', create_file = True)\n",
    "filter_by_english_thresholds(1, 1.01, 'data/Kingston/24400_tweets_over_period.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
